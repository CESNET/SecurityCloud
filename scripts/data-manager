#!/usr/bin/env python3

# author: Jan Wrona, wrona@cesnet.cz

# Copyright (C) 2017 CESNET
#
# LICENSE TERMS
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in
#    the documentation and/or other materials provided with the
#    distribution.
# 3. Neither the name of the Company nor the names of its contributors
#    may be used to endorse or promote products derived from this
#    software without specific prior written permission.
#
# ALTERNATIVELY, provided that this notice is retained in full, this
# product may be distributed under the terms of the GNU General Public
# License (GPL) version 2 or later, in which case the provisions
# of the GPL apply INSTEAD OF those given above.
#
# This software is provided ``as is'', and any express or implied
# warranties, including, but not limited to, the implied warranties of
# merchantability and fitness for a particular purpose are disclaimed.
# In no event shall the company or contributors be liable for any
# direct, indirect, incidental, special, exemplary, or consequential
# damages (including, but not limited to, procurement of substitute
# goods or services; loss of use, data, or profits; or business
# interruption) however caused and on any theory of liability, whether
# in contract, strict liability, or tort (including negligence or
# otherwise) arising in any way out of the use of this software, even
# if advised of the possibility of such damage.


import os
import sys
import re
import math
import argparse
import datetime
import warnings
from pathlib import Path


OUTPUT_PREFIX = os.path.basename(__file__).upper() if '__file__' in globals() \
    else 'DATA-MANAGER'

DU_UPPER_BOUND_LIMIT = 95.0
DU_LOWER_BOUND_LIMIT = 5.0
DU_BOUND_DIFFERENCE_LIMIT = 10.0

# strftime()/strptime() translation table
STRTIME_DICT = {'year': '%Y', 'month': '%m', 'day': '%d', 'hour': '%H',
                'minute': '%M', 'second': '%S'}
# strftime()/strptime() formats for YYYYMMDDHHMM and YYYYMMDDHHMMSS
STRTIME_FORMAT_YMDHM = (STRTIME_DICT['year'] + STRTIME_DICT['month']
                        + STRTIME_DICT['day'] + STRTIME_DICT['hour']
                        + STRTIME_DICT['minute'])
STRTIME_FORMAT_YMDHMS = STRTIME_FORMAT_YMDHM + STRTIME_DICT['second']
# re match pattern for YYYYMMDDHHMM or YYYYMMDDHHMMSS
DATETIME_PATTERN = (r'(?P<year>\d{4})(?P<month>\d{2})(?P<day>\d{2})'
                    r'(?P<hour>\d{2})(?P<minute>\d{2})'
                    r'(?P<second>\d{2})?')
# precompiled regex for YYYYMMDDHHMM or YYYYMMDDHHMMSS
DATETIME_REGEX = re.compile(DATETIME_PATTERN, re.ASCII)

# metric prefixes for int_prefix()
METRIC_PREFIXES = 'kMGTPEZYyzafpnÂµm'


###############################################################################
class Node:
    """Representation of a node with multiple base profiles.

    In the usual case, list of base profiles contains just a single base
    profile called "live".
    """

    def __init__(self, path):
        self.path = path
        self.profiles = []

    def __repr__(self):
        return '{}(name={}, profiles={})'.format(type(self).__name__,
                                                 self.path.name, self.profiles)

    def scan(self):
        """Scan node's base directory and look for base profiles.

        Scan node's base directory, look for profiles and eventually
        recursively construct those profiles as instances of class Profile.
        """

        self.profiles.clear()

        vprint('node directory "{}" scan:'.format(self.path.name), end=' ')
        content_dict = dir_scan(self.path)
        vprint('using dirs: {}, ignoring: {}'
               .format(content_dict['dirs_n'], content_dict['others_n']),
               use_prefix=False)
        for profile_dir in content_dict['dirs']:
            profile = Profile(profile_dir, self)
            profile.scan()
            self.profiles.append(profile)


class Profile:
    """IPFIXcol profile/subprofile representation."""

    def __init__(self, path, parent):
        self.path = path  # pathlib path to the profile's base directory
        self.parent = parent  # profile's parent Profile or Node
        self.channels = []  # list of instances of Channel
        self.subprofiles = []  # list of instances of Profile

    def __repr__(self):
        return '{}(name={}, parent={}, channels={}, subprofiles={})'\
            .format(type(self).__name__, self.path.name, self.parent.path.name,
                    self.channels, self.subprofiles)

    def scan(self):
        """Scan profile's base directory and look for channels and subprofiles.

        Scan profile's base directory and look for for channels (directory
        "channels"), ignore directory with RRD files "rrd", also ignore hidden
        directories. All other directories are assumed to be subprofiles and
        are recursively constructed as instances of class Profile.
        """

        self.channels.clear()
        self.subprofiles.clear()

        vprint('profile directory "{}" scan:'.format(self.path.name), end=' ')
        content_dict = dir_scan(self.path)
        # further separate found directories into channels directory, rrd
        # directory, and other directories == subprofile directories
        for subdir in content_dict['dirs']:
            if subdir.name == 'channels' or subdir.name == 'rrd':
                content_dict[subdir.name + '_dir'] = subdir
                content_dict[subdir.name + '_dir_n'] = subdir.name
            else:
                content_dict.setdefault('subprofile_dirs', set()).add(subdir)
                content_dict.setdefault('subprofile_dirs_n', set()).add(
                    subdir.name)
        content_dict.setdefault('subprofile_dirs', set())
        content_dict.setdefault('subprofile_dirs_n')
        content_dict.setdefault('rrd_dir')
        content_dict.setdefault('rrd_dir_n')

        if 'channels_dir' not in content_dict:
            raise Exception('profile "{}" is missing the "channels" directory'
                            .format(self.path.name))
        vprint('channels dir: {}, RRD dir: {}, subprofiles list: {}, '
               'ignoring files: {}'.format(content_dict['channels_dir_n'],
                                           content_dict['rrd_dir_n'],
                                           content_dict['subprofile_dirs_n'],
                                           content_dict['others_n']),
               use_prefix=False)

        # scan channels directory
        vprint('channels directory "{}" scan:'
               .format(content_dict['channels_dir'].name), end=' ')
        ch_content_dict = dir_scan(content_dict['channels_dir'])
        vprint('using dirs: {}, ignoring files: {}'
               .format(ch_content_dict['dirs_n'], ch_content_dict['others_n']),
               use_prefix=False)
        for channel_dir in ch_content_dict['dirs']:
            channel = self.Channel(channel_dir, self)
            channel.scan()
            self.channels.append(channel)

        for subprofile_dir in content_dict['subprofile_dirs']:
            subprofile = Profile(subprofile_dir, self)
            subprofile.scan()
            self.subprofiles.append(subprofile)

    def get_channels(self, recursively=False):
        """Return a list of subprofiles, recursively or not."""

        channels = list(self.channels)  # make a copy
        if recursively:
            for subprofile in self.subprofiles:
                channels += subprofile.get_channels(recursively)
        return channels

    class Channel:
        """IPFIXcol channel representation."""

        def __init__(self, path, parent):
            self.path = path  # pathlib path to the channel's base directory
            self.parent = parent  # channel's parent Profile
            self.flow_files = []  # list of instances of FlowFile

        def __repr__(self):
            return ('{}(name={}, parent={}, earliest_flow_file={}, '
                    'latest_flow_file={})'
                    .format(type(self).__name__, self.path.name,
                            self.parent.path.name,
                            self.get_earliest_flow_file(),
                            self.get_latest_flow_file()))

        def is_empty(self):
            return False if self.flow_files else True

        def get_earliest_flow_file(self):
            return self.flow_files[0] if not self.is_empty() else None

        def get_latest_flow_file(self):
            return self.flow_files[-1] if not self.is_empty() else None

        def remove_empty_parent_directories(self, flow_file):
            """Only works with YYYY/MM/DD directory hierarchy."""

            if flow_file.name_datetime.date() != flow_file.path_date:
                warnings.warn('remove empty parent directories: "{}": '
                              'path/name date mismatch, unable to remove '
                              'empty directories'.format(flow_file.path))
                return

            parent_dir = flow_file.path.parent
            for i in ['day', 'month', 'year']:
                if dir_is_empty(parent_dir):
                    if args.dry_run:
                        dprint('would remove empty {} directory "{}"'
                               .format(i, parent_dir))
                    else:
                        vprint('removing empty {} directory "{}"'
                               .format(i, parent_dir))
                        parent_dir.rmdir()
                else:
                    break
                parent_dir = parent_dir.parent

        def scan(self):
            """Scan channel's base directory and look for flow files."""

            self.flow_files.clear()

            vprint('channel directory "{}" scan:'.format(self.path.name),
                   end=' ')
            for path in self.path.rglob('*'):  # recursively list all files
                if not path.is_file():
                    continue
                elif path.name.startswith('.'):
                    warnings.warn('channel scan: found invalid file "{}" '
                                  'in "{}" channel storage hierarchy, skipping'
                                  .format(path, self.path.name))

                flow_file = self.FlowFile(path, self)
                try:
                    flow_file.parse_path()
                except ValueError as e:
                    warnings.warn(e.args[0] + ', skipping')
                    continue

                self.flow_files.append(flow_file)
            self.flow_files.sort(key=lambda flow_file: flow_file.name_datetime)

            if self.flow_files:
                vprint('found {} flow files, earliest from {}, latest from {}'
                       .format(len(self.flow_files),
                               self.get_earliest_flow_file().name_datetime,
                               self.get_latest_flow_file().name_datetime),
                       use_prefix=False)
            else:
                vprint('found 0 flow files', use_prefix=False)

        class FlowFile:
            """Flow file representation."""

            def __init__(self, path, parent):
                self.path = path  # pathlib path to the file
                self.parent = parent  # file's parent Channel
                self.name_datetime = None
                self.path_date = None

                self._size = None  # never use directly, always use get_size()

            def __repr__(self):
                return ('{}(name={}, parent={}, name_datetime={}, '
                        'path_date={})'.format(type(self).__name__,
                                               self.path.name,
                                               self.parent.path.name,
                                               self.name_datetime,
                                               self.path_date))

            def __lt__(self, other):
                return self.name_datetime < other.name_datetime

            def __le__(self, other):
                return self.name_datetime <= other.name_datetime

            def __eq__(self, other):
                return self.name_datetime == other.name_datetime

            def __gt__(self, other):
                return self.name_datetime > other.name_datetime

            def __ge__(self, other):
                return self.name_datetime >= other.name_datetime

            def parse_path(self):
                """Discover date and time from file's path.

                Search for patterns YYYYMMDDHHMM or YYYYMMDDHHMMSS in the
                file's name and if found, convert the match into corresponding
                datetime object. Then check if file's directory hierarchy
                comply with YYYY/MM/DD format.
                """

                match = DATETIME_REGEX.search(self.path.name)
                if not match:
                    raise ValueError('flow file parse path: patterns '
                                     'YYYYMMDDHHMM or YYYYMMDDHHMMSS not '
                                     'found in file\'s "{}" name'
                                     .format(self.path))

                if match.group('second'):
                    strtime_format = STRTIME_FORMAT_YMDHMS
                else:
                    strtime_format = STRTIME_FORMAT_YMDHM
                self.name_datetime = datetime.datetime.strptime(match.group(0),
                                                                strtime_format)
                try:
                    day = int(self.path.parent.name)
                    month = int(self.path.parent.parent.name)
                    year = int(self.path.parent.parent.parent.name)
                    self.path_date = datetime.date(year, month, day)
                except Exception:
                    warnings.warn('flow file parse path: "{}" does not comply '
                                  'with YYYY/MM/DD directory hierarchy'
                                  .format(self.path))
                if self.name_datetime.date() != self.path_date:
                    warnings.warn('flow file parse path: path/name date '
                                  'mismatch, name corresponds to "{}", path '
                                  'corresponds to "{}"'
                                  .format(self.name_datetime, self.path_date))

            def get_size(self):
                """Return size of the flow file in bytes. Lazy."""

                if not self.path.exists():
                    raise FileNotFoundError
                elif not self._size:
                    self._size = os.stat(str(self.path)).st_size
                return self._size

            def unlink(self):
                if args.dry_run:
                    dprint('would unlink "{}" of {}B'
                           .format(self.path, int_prefix_str(self.get_size())))
                else:
                    vprint('unlinking "{}" of {}B'
                           .format(self.path, int_prefix_str(self.get_size())))
                    self.path.unlink()


###############################################################################
def vprint_formatter(*args, **kwargs):
    """Verbose-enabled print formatter."""
    if 'use_prefix' in kwargs:
        use_prefix = kwargs['use_prefix']
        del(kwargs['use_prefix'])
    else:
        use_prefix = True

    if use_prefix:
        print(OUTPUT_PREFIX, 'VERBOSE:', *args, **kwargs)
    else:
        print(*args, **kwargs)


def vprint_formatter_void(*args, **kwargs):
    """Verbose-disabled print formatter."""
    pass


def myformatwarning(message, category, filename, lineno, line=None):
    return '{} WARNING: {}\n'.format(OUTPUT_PREFIX, str(message))


###############################################################################
def main():
    rc = 0

    # check if used disk space is below the given upper bound
    du_before = disk_usage(base_path)
    if du_before[2] < args.du_upper_bound:
        vprint('nothing to do, used disk space is below the given upper bound '
               '({:.2f} % < {:.2f} %)'.format(du_before[2],
                                              args.du_upper_bound))
        return 0

    # find node directories in the base path
    vprint('base directory "{}" scan:'.format(base_path), end=' ')
    content_dict = dir_scan(base_path)
    vprint('using dirs: {}, ignoring files: {}'
           .format(content_dict['dirs_n'], content_dict['others_n']),
           use_prefix=False)
    if not content_dict['dirs']:
        raise Exception('node directory lookup: nothing appropriate found in '
                        'the given directory')

    # check if all node directories are placed on the same device
    ref_st_dev = next(iter(content_dict['dirs'])).stat().st_dev
    if not all(ref_st_dev == node_dir.stat().st_dev
               for node_dir in content_dict['dirs']):
        raise Exception('node directory lookup: one or more node directories '
                        'are placed on different devices')

    # scan all node directories and create profiles, recursively
    nodes = []
    for path in content_dict['dirs']:
        node = Node(path)
        node.scan()
        nodes.append(node)

    # get list of all channels, recursively
    all_channels = []
    for node in nodes:
        for profile in node.profiles:
            all_channels += profile.get_channels(recursively=True)

    files_cnt = 0
    columns_cnt = 0
    bytes_cnt = 0
    if args.du_lower_bound:
        # calculate difference between current disk usage and desired disk
        # usage (aka lower bound) in bytes
        statvfs = os.statvfs(str(path))
        used_blocks = statvfs.f_blocks - statvfs.f_bavail
        desired_blocks = int(statvfs.f_blocks * (args.du_lower_bound / 100.0))
        bytes_cnt = (used_blocks - desired_blocks) * statvfs.f_frsize
    else:
        files_cnt = 1

    vprint('unlinking {} files, {} columns, {} bytes'.format(files_cnt,
           columns_cnt, int_prefix_str(bytes_cnt)))
    unlinked_files = unlink_earliest(all_channels, files_cnt=files_cnt,
                                     columns_cnt=columns_cnt,
                                     bytes_cnt=bytes_cnt)
    if unlinked_files <= 0:
        unlinked_files = -unlinked_files
        warnings.warn('all channels are empty, cannot reach lower '
                      'bound of disk usage ({:.2f} %)'
                      .format(args.du_lower_bound))

    du_after = disk_usage(base_path)
    vprint('summary: {} {} files, used disk space '
           'before = {}B ({:.2f} %), '
           'after = {}B ({:.2f} %), '
           'difference = {}B, '
           .format('would unlink' if args.dry_run else 'unlinked',
                   unlinked_files, int_prefix_str(du_before[1]), du_before[2],
                   int_prefix_str(du_after[1]), du_after[2],
                   int_prefix_str(abs(du_before[1] - du_after[1]))))
    return rc


def disk_usage(path):
    """
    Return the amount of disk space used on the file system containing given
    path.

    statvfs.f_blocks is size of fs in f_frsize units
    statvfs.f_bavail is number of free blocks for unprivileged users
    """

    path = str(path)  # for backward compatibility with Python < 3.6
    statvfs = os.statvfs(path)
    used_blocks = statvfs.f_blocks - statvfs.f_bavail

    # (block, bytes, percentual)
    return (used_blocks, used_blocks * statvfs.f_frsize,
            used_blocks / statvfs.f_blocks * 100.0)


def dir_scan(path):
    """
    Wrapper for Path.iterdir(), which returns dictionaty containing separate
    sets for directories (keys dirs and dirs_n) and other content (keys
    others and others_n).
    """
    dir_content = {}
    for file in path.iterdir():
        if not file.is_dir() or file.name.startswith('.'):
            dir_content.setdefault('others', set()).add(file)
            dir_content.setdefault('others_n', set()).add(file.name)
        else:
            dir_content.setdefault('dirs', set()).add(file)
            dir_content.setdefault('dirs_n', set()).add(file.name)

    dir_content.setdefault('dirs')
    dir_content.setdefault('dirs_n')
    dir_content.setdefault('others')
    dir_content.setdefault('others_n')
    return dir_content


def dir_is_empty(path):
    return not any(True for _ in path.iterdir())


def min_all(iterable, selector):
        """Return list of all smallest items in an iterable."""
        smallest = min(iterable, key=selector)
        smallest_selected = selector(smallest)
        return [i for i in iterable if selector(i) == smallest_selected]


def unlink_earliest(channels, files_cnt=1, columns_cnt=0, bytes_cnt=0,
                    alignment=datetime.timedelta(minutes=1)):
    if not (files_cnt or columns_cnt or bytes_cnt):
        raise ValueError('one of files_cnt, columns_cnt, or bytes_cnt has to '
                         'be specified')
    if files_cnt and files_cnt < 0:
        raise ValueError('files_cnt has to be a positive integer')
    if columns_cnt and columns_cnt < 0:
        raise ValueError('columns_cnt has to be a positive integer')
    if bytes_cnt and bytes_cnt < 0:
        raise ValueError('bytes_cnt has to be a positive integer')

    # get a sorted list (earlier first) of all flow files from all channels
    all_files = []
    for channel in channels:
        all_files += channel.flow_files
    all_files.sort()

    # regular removal
    unlinked_files = 0  # number of unlinked files
    unlinked_columns = 0  # number of unlinked columns of files
    unlinked_bytes = 0  # size of all unlinked files in bytes
    while all_files:
        if ((files_cnt and unlinked_files == files_cnt)
                or (columns_cnt and unlinked_columns == columns_cnt)
                or (bytes_cnt and unlinked_bytes >= bytes_cnt)):
            break
        flow_file = all_files.pop(0)  # retireve and remove
        unlinked_files += 1
        unlinked_columns += (flow_file.name_datetime !=
                             next(iter(all_files),
                                  Profile.Channel.FlowFile(None, None))
                             .name_datetime)
        unlinked_bytes += flow_file.get_size()
        flow_file.unlink()
        print('regular: ', unlinked_files, unlinked_columns, unlinked_bytes)

    # removal due to alignment
    ref_datetime = flow_file.name_datetime
    while all_files and alignment:
        delta = all_files[0].name_datetime - ref_datetime
        if delta > alignment:
            break
        flow_file = all_files.pop(0)  # retireve and remove
        unlinked_files += 1
        unlinked_columns += (flow_file.name_datetime !=
                             next(iter(all_files),
                                  Profile.Channel.FlowFile(None, None))
                             .name_datetime)
        unlinked_bytes += flow_file.get_size()
        flow_file.unlink()
        print('alignment: ', unlinked_files, unlinked_columns, unlinked_bytes)

    if unlinked_bytes < bytes_cnt:
        return -unlinked_files  # could not reach lower bound
    else:
        return unlinked_files  # lower bound reached


def int_prefix(num):
    num = int(num)
    if abs(num) < 1000:
        return (num, None)

    order = math.floor(math.log10(abs(num)))
    div, mod = divmod(order, 3)
    new_num = num * (10 ** (-order + mod))
    return (new_num, METRIC_PREFIXES[div - 1])


def int_prefix_str(num, format_string='{0:.2f} {1}'):
    new_num, prefix = int_prefix(num)
    if prefix:
        return format_string.format(new_num, prefix)
    else:
        return str(num) + ' '


###############################################################################
if __name__ == "__main__":
    # set my format for warning print function
    warnings.formatwarning = myformatwarning

    ########################################
    # parse command line arguments
    parser = argparse.ArgumentParser(
        description='Flow file data manager.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument('-u', '--du-upper-bound',
                        dest='du_upper_bound',
                        type=float,
                        default=90.0,
                        help='Percentual upper bound of disk usage.')
    parser.add_argument('-l', '--du-lower-bound',
                        dest='du_lower_bound',
                        type=float,
                        default=None,
                        help='Percentual lower bound of disk usage.')
    parser.add_argument('-n', '--dry-run',
                        dest='dry_run',
                        action='store_true',
                        default=False,
                        help='Don\'t actually remove anything, just show what '
                             'would be done.')
    parser.add_argument('-v', '--verbose',
                        dest='verbose',
                        action='store_true',
                        default=False,
                        help='Be verbose.')

    parser.add_argument('base_path',
                        nargs=1,
                        help='Path to the flow storage directory.')
    args = parser.parse_args()

    ########################################
    # validate and handle command line arguments
    # define a verbose print function and a dry run print function
    vprint = vprint_formatter if args.verbose else vprint_formatter_void
    dprint = print

    # check validity of given bounds
    if args.du_lower_bound and args.du_lower_bound > args.du_upper_bound:
        raise ValueError('the lower bound is greater than the upper bound')
    if (args.du_lower_bound and args.du_upper_bound - args.du_lower_bound >
            DU_BOUND_DIFFERENCE_LIMIT):
        raise ValueError('the lower and upper bound difference is dangerously '
                         'large')
    if args.du_upper_bound > DU_UPPER_BOUND_LIMIT:
        raise ValueError('the upper bound is dangerously high')
    if args.du_lower_bound and args.du_lower_bound < DU_LOWER_BOUND_LIMIT:
        raise ValueError('the lower bound is dangerously low')

    # check validity of given base path
    base_path = Path(args.base_path[0])
    if not base_path.exists():
        raise FileNotFoundError('"{}" does not exist'.format(base_path))
    if not base_path.is_dir():
        raise NotADirectoryError('"{}" does not point to a directory'
                                 .format(base_path))

    ########################################
    # do the real work
    sys.exit(main())
